import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import geopandas as gpd
import os
import glob
import pandas as pd
import re
from shapely.geometry import Point
from scipy.interpolate import griddata
import platform
import rasterio
from rasterio.features import rasterize
from rasterio.mask import mask
from rasterio.transform import from_origin
import io
import tempfile
from sqlalchemy import create_engine

from utils.color_palettes import ALL_PALETTES, get_palette_preview_html
from utils.theme_util import apply_theme_toggle

engine = create_engine("postgresql://postgres:asdfasdf12@localhost:5432/gisdb")

# ----- Streamlit í˜ì´ì§€/í°íŠ¸ ì„¸íŒ… -----
pixel_size = 1
if platform.system() == "Windows":
    plt.rc("font", family="Malgun Gothic")
else:
    plt.rc("font", family="AppleGothic")
plt.rcParams["axes.unicode_minus"] = False

st.set_page_config(
    page_title="ë˜ì´ˆìë£Œ ìš´ì‚¬ì› - ê²°ê³¼",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="collapsed",
)
main_col = apply_theme_toggle()
st.markdown(
    """
<style>
.big-text { font-size: 24px !important; font-weight: bold; }
.result-text { font-size: 18px !important; font-weight: bold; }
.stButton>button {
    width: 100%;
    border-radius: 20px !important;
    font-size: 18px !important;
    padding: 10px 24px !important;
}
</style>
""",
    unsafe_allow_html=True,
)

# ----- ì„¸ì…˜ ìƒíƒœ ì²´í¬ -----
if "uploaded_file" not in st.session_state or st.session_state.uploaded_file is None:
    st.error("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë©”ì¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ì„¸ìš”.")
    if st.button("ë©”ì¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
        st.switch_page("app.py")
    st.stop()
if "processing_done" not in st.session_state:
    st.error("ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ í˜ì´ì§€ë¡œ ëŒì•„ê°€ì„¸ìš”.")
    if st.button("ì´ì „ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
        st.switch_page("pages/03_ì²˜ë¦¬ì¤‘.py")
    st.stop()
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = {
        "done": True,
        "message": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
        "palettes": {"elevation": "terrain", "slope": "RdYlBu"},
    }

elevation_palette = st.session_state.analysis_results["palettes"]["elevation"]
slope_palette = st.session_state.analysis_results["palettes"]["slope"]


# ----- ì¢Œí‘œ ë¬¸ìì—´ íŒŒì‹± í•¨ìˆ˜ -----
def parse_coordinate_string(coord_str):
    match = re.match(r"([\d\-. ]+)[, ]+([\d\-. ]+)", coord_str)
    if not match:
        return None
    lat_str, lon_str = match.group(1), match.group(2)

    def dms_to_deg(s):
        s = (
            s.replace(",", " ")
            .replace("-", " ")
            .replace("Â°", " ")
            .replace("'", " ")
            .replace('"', " ")
        )
        parts = [float(x) for x in re.split(r"\s+", s.strip()) if x]
        if len(parts) == 3:
            deg, minute, sec = parts
            return deg + (minute / 60) + (sec / 3600)
        elif len(parts) == 2:
            deg, minute = parts
            return deg + (minute / 60)
        else:
            return float(parts[0])

    lat = dms_to_deg(lat_str)
    lon = dms_to_deg(lon_str)
    return Point(lon, lat)


# ----- ëª¨ë“  geometryì—ì„œ point ì¶”ì¶œ -----
def extract_points(gdf, elevation_field):
    xs, ys, zs = [], [], []
    for idx, row in gdf.iterrows():
        geom = row.geometry
        z = row[elevation_field]
        if geom is None or geom.is_empty:
            continue
        if geom.geom_type == "Point":
            xs.append(geom.x)
            ys.append(geom.y)
            zs.append(z)
        elif geom.geom_type == "MultiPoint":
            for pt in geom.geoms:
                xs.append(pt.x)
                ys.append(pt.y)
                zs.append(z)
        elif geom.geom_type == "LineString":
            for pt in geom.coords:
                xs.append(pt[0])
                ys.append(pt[1])
                zs.append(z)
        elif geom.geom_type == "MultiLineString":
            for line in geom.geoms:
                for pt in line.coords:
                    xs.append(pt[0])
                    ys.append(pt[1])
                    zs.append(z)
        elif geom.geom_type == "Polygon":
            for pt in geom.exterior.coords:
                xs.append(pt[0])
                ys.append(pt[1])
                zs.append(z)
        elif geom.geom_type == "MultiPolygon":
            for poly in geom.geoms:
                for pt in poly.exterior.coords:
                    xs.append(pt[0])
                    ys.append(pt[1])
                    zs.append(z)
    return np.array(xs), np.array(ys), np.array(zs)


# ----- í‘œê³  í†µê³„ -----
def calc_elevation_stats(array):
    arr = array[np.isfinite(array)]
    return {
        "min": float(np.nanmin(arr)) if arr.size > 0 else np.nan,
        "max": float(np.nanmax(arr)) if arr.size > 0 else np.nan,
        "mean": float(np.nanmean(arr)) if arr.size > 0 else np.nan,
        "area": arr.size,
    }


# ----- ìºì‹œ/ì„ì‹œíŒŒì¼ ì ê·¹ í™œìš© -----
@st.cache_data(show_spinner=False)
def merge_and_standardize(
    user_shp_path,
    sample_shp_files,
    altitude_cols,
    geometry_cols,
    elevation_field,
    target_crs,
):
    dfs = []
    for shp_path in [user_shp_path] + sample_shp_files:
        try:
            gdf = gpd.read_file(shp_path)
            geom_col = next((col for col in geometry_cols if col in gdf.columns), None)
            if geom_col and geom_col != "geometry":
                gdf = gdf.rename(columns={geom_col: "geometry"})
            if "geometry" not in gdf.columns and "ì¢Œí‘œ" in gdf.columns:
                gdf["geometry"] = gdf["ì¢Œí‘œ"].apply(parse_coordinate_string)
            elif gdf["geometry"].dtype == "object" and all(
                isinstance(val, str) for val in gdf["geometry"]
            ):
                gdf["geometry"] = gdf["geometry"].apply(parse_coordinate_string)
            found_col = next((col for col in altitude_cols if col in gdf.columns), None)
            if found_col and found_col != elevation_field:
                gdf = gdf.rename(columns={found_col: elevation_field})
            if elevation_field not in gdf.columns:
                gdf[elevation_field] = np.nan
            gdf = gdf.set_geometry("geometry")
            if gdf.crs is None:
                gdf.set_crs("EPSG:4326", inplace=True)
            gdf = gdf.to_crs(target_crs)
            gdf = gdf[gdf["geometry"].notna() & (~gdf["geometry"].is_empty)]
            gdf = gdf[~gdf[elevation_field].isna()]
            dfs.append(gdf[["geometry", elevation_field]])
        except Exception as e:
            st.warning(f"{shp_path} ì½ê¸° ì‹¤íŒ¨: {e}")
    if dfs:
        merged_gdf = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True), crs=dfs[0].crs)
        return merged_gdf
    else:
        return None


def merge_and_standardize_gdf_list(
    gdf_list, altitude_cols, geometry_cols, elevation_field, target_crs
):
    dfs = []
    for gdf in gdf_list:
        try:
            # geometry ì»¬ëŸ¼ëª… í‘œì¤€í™”
            geom_col = next((col for col in geometry_cols if col in gdf.columns), None)
            if geom_col and geom_col != "geometry":
                gdf = gdf.rename(columns={geom_col: "geometry"})
            found_col = next((col for col in altitude_cols if col in gdf.columns), None)
            if found_col and found_col != elevation_field:
                gdf = gdf.rename(columns={found_col: elevation_field})
            if elevation_field not in gdf.columns:
                gdf[elevation_field] = np.nan
            gdf = gdf.set_geometry("geometry")
            if gdf.crs is None:
                gdf.set_crs("EPSG:4326", inplace=True)
            gdf = gdf.to_crs(target_crs)
            gdf = gdf[gdf["geometry"].notna() & (~gdf["geometry"].is_empty)]
            gdf = gdf[~gdf[elevation_field].isna()]
            dfs.append(gdf[["geometry", elevation_field]])
        except Exception as e:
            st.warning(f"gdf ë³‘í•© ì‹¤íŒ¨: {e}")
    if dfs:
        merged_gdf = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True), crs=dfs[0].crs)
        return merged_gdf
    else:
        return None


# ---- ë°ì´í„° ì¤€ë¹„ (ì„ì‹œíŒŒì¼/ìºì‹œ ì‚¬ìš©) ----
with st.expander("ğŸ” ì—…ë¡œë“œ/ìƒ˜í”Œ ë„ì—½ ë³‘í•© + DEM ë³´ê°„ ë° í´ë¦¬í•‘ ê²°ê³¼", expanded=True):

    user_shp_path = st.session_state.get(
        "temp_file_path", None
    ) or st.session_state.get("uploaded_file_path", None)
    if not user_shp_path or not os.path.exists(user_shp_path):
        st.error(
            "ì—…ë¡œë“œ í´ë¦¬ê³¤ shp íŒŒì¼ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. (session_state['temp_file_path'])"
        )
        st.stop()

    sample_shp_files = glob.glob(r"C:\dev\sample2\*.shp")
    if not sample_shp_files:
        st.error("C:\\dev\\sample2 í´ë”ì— ë„ì—½ ìƒ˜í”Œ shp íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    user_gdf = gpd.read_file(user_shp_path)

    sheet_str = ",".join([f"'{x}'" for x in sample_sheet_codes])
    sql = f"""
    SELECT geometry, elevation
    FROM nationwide_shp
    WHERE sheet_code IN ({sheet_str})
    """

    # GeoDataFrameìœ¼ë¡œ ì½ê¸°
    sample_gdf = gpd.read_postgis(sql, engine, geom_col="geometry")

    altitude_cols = [
        "í‘œê³ ",
        "ë“±ê³ ìˆ˜ì¹˜",
        "ìˆ˜ì¹˜",
        "ê³ ë„",
        "elev",
        "elevation",
        "height",
        "Z",
    ]
    geometry_cols = ["geometry", "Geometry", "GEOMETRY", "geom", "Geom", "ì¢Œí‘œ"]
    elevation_field = "elevation"
    target_crs = "EPSG:5186"

    merged_gdf = merge_and_standardize(
        user_shp_path,
        sample_shp_files,
        altitude_cols,
        geometry_cols,
        elevation_field,
        target_crs,
    )
    if merged_gdf is None or len(merged_gdf) == 0:
        st.error("ë„ì—½ ë³‘í•© ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.")
        st.stop()
    st.success(f"ì—…ë¡œë“œ+ë„ì—½ ë³‘í•© ì™„ë£Œ! ì´ {len(merged_gdf)}ê°œ ê°ì²´")

    # ---- DEM ë³´ê°„ ë° tif ì„ì‹œì €ì¥ ----
    with tempfile.NamedTemporaryFile(suffix=".tif", delete=False) as tmpfile:
        tif_path = tmpfile.name

    with st.spinner("DEM ë³´ê°„ ì¤‘..."):
        xs, ys, zs = extract_points(merged_gdf, elevation_field)
        minx, miny, maxx, maxy = merged_gdf.total_bounds
        grid_x, grid_y = np.mgrid[minx:maxx:pixel_size, miny:maxy:pixel_size]
        dem_grid = griddata(
            (xs, ys), zs, (grid_x, grid_y), method="linear", fill_value=np.nan
        )
        transform = from_origin(minx, maxy, pixel_size, pixel_size)
        with rasterio.open(
            tif_path,
            "w",
            driver="GTiff",
            height=dem_grid.shape[1],
            width=dem_grid.shape[0],
            count=1,
            dtype="float32",
            crs=merged_gdf.crs,
            transform=transform,
            nodata=np.nan,
        ) as dst:
            dst.write(np.flipud(dem_grid.T), 1)
        st.success("DEM ë³´ê°„ ì™„ë£Œ!")

    # ---- í´ë¦¬í•‘ ----
    with st.spinner("ì‚¬ìš©ì í´ë¦¬ê³¤ìœ¼ë¡œ DEM í´ë¦¬í•‘ ì¤‘..."):
        user_gdf = gpd.read_file(user_shp_path).to_crs(merged_gdf.crs)
        clip_geoms = [g for g in user_gdf.geometry if g.is_valid and not g.is_empty]
        with rasterio.open(tif_path) as src:
            clipped, clipped_transform = mask(src, clip_geoms, crop=True, nodata=np.nan)
            clipped_dem = clipped[0]
        st.success("í´ë¦¬í•‘ ì™„ë£Œ!")

    # ---- í†µê³„ session_state ì €ì¥ ----
    stats = calc_elevation_stats(clipped_dem)
    st.session_state["dem_results"] = {
        "elevation": {"stats": stats, "grid": clipped_dem}
    }

# ----- ì‹œê°í™”/ì»¬ëŸ¬ë§µ/ë‹¤ìš´ë¡œë“œ -----
st.markdown("## ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆì–´ìš”")
selected_types = st.session_state.get("selected_analysis_types", [])

if "dem_results" in st.session_state and st.session_state.dem_results:
    dem_results = st.session_state.dem_results
    if "elevation" in selected_types and dem_results["elevation"]["stats"]:
        elev_stats = dem_results["elevation"]["stats"]
        st.markdown(
            f"## í‘œê³ ëŠ” {elev_stats['min']:.1f}~{elev_stats['max']:.1f}m, í‰ê· í‘œê³ ëŠ” {elev_stats['mean']:.1f}më¡œ ë¶„ì„ë˜ì—ˆì–´ìš”."
        )

# ---- ì»¬ëŸ¬ë§µë³„ íƒ­ ì‹œê°í™” ë° ë‹¤ìš´ë¡œë“œ ----
elev_cmaps = ["terrain", "gist_earth", "viridis", "Spectral"]
if "elevation" in selected_types:
    st.markdown("### í‘œê³  ë¶„ì„ ì»¬ëŸ¬ë§µ ë¯¸ë¦¬ë³´ê¸°")
    tabs = st.tabs(elev_cmaps)
    mask = ~np.isnan(clipped_dem)
    if not np.any(mask):
        st.warning("í´ë¦¬í•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        rows = np.any(mask, axis=1)
        cols = np.any(mask, axis=0)
        min_row, max_row = np.where(rows)[0][[0, -1]]
        min_col, max_col = np.where(cols)[0][[0, -1]]
        clipped_cropped = clipped_dem[min_row : max_row + 1, min_col : max_col + 1]
        for i, cmap in enumerate(elev_cmaps):
            with tabs[i]:
                fig, ax = plt.subplots(figsize=(7, 4))
                im = ax.imshow(np.ma.masked_invalid(clipped_cropped), cmap=cmap)
                plt.colorbar(im, ax=ax, label="Elevation(m)")
                ax.set_title(f"í´ë¦¬í•‘ëœ DEM - {cmap}")
                ax.axis("off")
                buf = io.BytesIO()
                plt.savefig(buf, format="png", bbox_inches="tight", pad_inches=0)
                buf.seek(0)
                plt.close(fig)
                image_bytes = buf.getvalue()
                st.image(image_bytes, caption=f"{cmap} ì‹œê°í™”", width=480)
                st.download_button(
                    label=f"{cmap} PNG ë‹¤ìš´ë¡œë“œ",
                    data=image_bytes,
                    file_name=f"dem_{cmap}.png",
                    mime="image/png",
                    key=f"download_{cmap}",
                )

# ---- ì˜ˆì‹œ: ì¶”ê°€ ë¶„ì„ ìœ í˜• ë“±... ----
# slope ë“± ë‹¤ë¥¸ ìœ í˜•ë„ ìœ„ ë°©ì‹ëŒ€ë¡œ ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥

# ---- ë‹¤ìš´ë¡œë“œ/ë§ˆë¬´ë¦¬ ----
col1, col2 = st.columns(2)
with col1:
    st.download_button(
        label="ê²°ê³¼(ìƒ˜í”Œ) ë‹¤ìš´ë¡œë“œ",
        data="ìƒ˜í”Œ ê²°ê³¼ ë°ì´í„°",
        file_name="result.txt",
        mime="text/plain",
        key="download_result_txt",
    )

st.markdown("---")
st.markdown("# ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
st.markdown("## ë˜ì´ˆìë£Œ ìš´ì‚¬ì›ì„ ì°¾ì•„ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”!")
st.markdown("## ë‹¤ìŒì— ë˜ ê¸°ì´ˆìë£Œ ì¡°ì‚¬ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë°©ë¬¸í•´ì£¼ì„¸ìš”!")
st.markdown("---")
st.markdown(
    """
### ìë£Œ ì¶œì²˜:
- DEM - êµ­í† ì§€ë¦¬ì •ë³´ì›
- í† ì§€í”¼ë³µë„ - í™˜ê²½ë¶€
- ì •ë°€í† ì–‘ë„ - ë†ì´Œì§„í¥ì²­
"""
)
st.markdown(
    """
ë˜ì´ˆìë£Œë¥¼ ì´ìš©í•˜ì‹œë©´ì„œ ë¶ˆí¸í•œ ì‚¬í•­ì´ ë°œìƒí•˜ê±°ë‚˜
ê°œì„  ë˜ëŠ” ë‹¤ì‹œ í•´ì£¼ì—ˆìœ¼ë©´ í•˜ëŠ” ìë£Œê°€ ìˆìœ¼ë©´ (ë©”ì¼ì£¼ì†Œ) ë¡œ ë¬¸ì˜ì£¼ì„¸ìš”!
ì œê°€ ìš´ì˜ì§„ë‹˜ê»˜ ì˜ ì „ë‹¬í•´ë“œë¦´ê²Œìš”
"""
)
st.markdown("---")
st.markdown("Published by Edward Yoon", unsafe_allow_html=True)
