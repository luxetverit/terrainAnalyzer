# -*- coding: utf-8 -*-
import glob
import os
import warnings
from tempfile import NamedTemporaryFile
import tempfile

import geopandas as gpd
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import rasterio
from rasterio.mask import mask
from rasterio.transform import from_origin
from scipy.interpolate import griddata
from sqlalchemy import create_engine
from matplotlib.patches import Rectangle

warnings.filterwarnings('ignore')

# ========== ì„¤ì • ==========
# DB ì—°ê²° ì„¤ì •
try:
    engine = create_engine(
        "postgresql://postgres:asdfasdf12@localhost:5432/gisDB")
    with engine.connect() as connection:
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
    engine = None

input_shp_dir = r"D:\\Python\\TerrainAnalyzer\\0.Input"
base_output_dir = r"D:\\Python\\TerrainAnalyzer\\1.basinstatus"
# pixel_size_csv ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
# pixel_size_csv = os.path.join(base_output_dir, "pixel_size_log.csv")
# pixel_df = pd.read_csv(pixel_size_csv)
os.makedirs(base_output_dir, exist_ok=True)

# í‘œê³  ì „ìš© ì‚¬ìš©ì ì •ì˜ ìƒ‰ìƒ
elevation_colors = {
    8: ['#66CDAA', '#FFFF00', '#008000', '#FFA500', '#8B0000', '#A52A2A', '#808080', '#FFFAFA'],
    10: ['#66CDAA', '#DDF426', '#71B800', '#558C00', '#F29300', '#981200', '#9C1C1C', '#955050', '#9C9B9B', '#FFFAFA']
}

# ê¸°ì¡´ ê²½ì‚¬ë„/ê²½ì‚¬í–¥ìš© ì»¬ëŸ¬ë§µ
colormaps = {
    'slope': ['YlOrRd', 'Reds', 'hot', 'copper', 'autumn'],
    'aspect': ['hsv', 'twilight', 'rainbow', 'gist_rainbow', 'nipy_spectral']
}

aspect_labels = ["North", "Northeast", "East",
                 "Southeast", "South", "Southwest", "West", "Northwest"]
aspect_bins = [0, 22.5, 67.5, 112.5, 157.5, 202.5, 247.5, 292.5, 337.5, 360]
interval_candidates = [1, 2, 3, 5, 10, 15, 20, 25, 50, 100, 150, 200, 500]


def create_hillshade(data, azimuth=315, altitude=45):
    """ê³ í’ˆì§ˆ ìŒì˜ê¸°ë³µë„(Hillshade) ìƒì„±"""
    # NaN ê°’ ì²˜ë¦¬
    valid_mask = ~np.isnan(data)
    if not np.any(valid_mask):
        return np.ones_like(data)

    # ê²½ì‚¬ë„ì™€ ê²½ì‚¬í–¥ ê³„ì‚°
    dy, dx = np.gradient(data)

    # ê²½ì‚¬ê° ê³„ì‚° (ë¼ë””ì•ˆ)
    slope = np.arctan(np.sqrt(dx**2 + dy**2))

    # ê²½ì‚¬í–¥ ê³„ì‚° (ë¼ë””ì•ˆ, ë¶ìª½ ê¸°ì¤€)
    aspect = np.arctan2(-dx, dy)

    # íƒœì–‘ ê°ë„ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
    azimuth_rad = np.radians(azimuth)
    altitude_rad = np.radians(altitude)

    # Hillshade ê³„ì‚°
    hillshade = (np.sin(altitude_rad) * np.sin(np.pi/2 - slope) +
                 np.cos(altitude_rad) * np.cos(np.pi/2 - slope) *
                 np.cos(azimuth_rad - aspect))

    # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    hillshade = np.clip(hillshade, 0, 1)

    # ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì—­ì€ 0.5ë¡œ ì„¤ì • (ì¤‘ê°„ ë°ê¸°)
    hillshade[~valid_mask] = 0.5

    return hillshade


def create_custom_elevation_colormap(colors, data, divisions):
    """í‘œê³ ìš© ì—°ì†ì ì¸ ì‚¬ìš©ì ì •ì˜ ì»¬ëŸ¬ë§µ ìƒì„±"""
    n_colors = len(colors)
    positions = np.linspace(0, 1, n_colors)

    color_dict = {
        'red': [],
        'green': [],
        'blue': []
    }

    for i, (pos, color) in enumerate(zip(positions, colors)):
        rgb = mcolors.hex2color(color)
        color_dict['red'].append((pos, rgb[0], rgb[0]))
        color_dict['green'].append((pos, rgb[1], rgb[1]))
        color_dict['blue'].append((pos, rgb[2], rgb[2]))

    cmap = mcolors.LinearSegmentedColormap(
        f'custom_elevation_{divisions}', color_dict)
    return cmap


def calculate_accurate_scalebar_params(pixel_size, img_shape, target_size_mm, fig, ax):
    """ì‹¤ì œ axes ì •ë³´ë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ìŠ¤ì¼€ì¼ë°” ê³„ì‚°"""
    fig_width_inch, fig_height_inch = fig.get_size_inches()
    ax_bbox = ax.get_position()

    img_width_fig = ax_bbox.width
    img_height_fig = ax_bbox.height

    img_height_pixels, img_width_pixels = img_shape

    img_width_inch = img_width_fig * fig_width_inch
    pixels_per_inch = img_width_pixels / img_width_inch

    target_size_inch = target_size_mm / 25.4
    target_pixels = target_size_inch * pixels_per_inch
    real_distance_m = target_pixels * pixel_size

    if real_distance_m < 100:
        scale_distance_m = round(real_distance_m / 50) * 50
        if scale_distance_m == 0:
            scale_distance_m = 50
        unit = 'm'
        scale_value = scale_distance_m
    elif real_distance_m < 1000:
        scale_distance_m = round(real_distance_m / 100) * 100
        unit = 'm'
        scale_value = scale_distance_m
    elif real_distance_m < 5000:
        scale_distance_km = round(real_distance_m / 500) * 0.5
        scale_distance_m = scale_distance_km * 1000
        unit = 'km'
        scale_value = scale_distance_km
    else:
        scale_distance_km = round(real_distance_m / 1000)
        scale_distance_m = scale_distance_km * 1000
        unit = 'km'
        scale_value = scale_distance_km

    actual_scalebar_width_fig = (
        scale_distance_m / pixel_size) / pixels_per_inch / fig_width_inch

    return {
        'length': scale_value,
        'units': unit,
        'segments': 2,
        'target_size_mm': target_size_mm,
        'real_distance_m': scale_distance_m,
        'scalebar_width_fig': actual_scalebar_width_fig
    }


def draw_accurate_scalebar(fig, ax, pixel_size, scale_params, img_shape):
    """ì •í™•í•œ ì¶•ì²™ ë°˜ì˜ ìŠ¤ì¼€ì¼ë°”"""
    total_length = scale_params['length']
    units = scale_params['units']
    segments = scale_params['segments']
    scalebar_width_fig = scale_params['scalebar_width_fig']

    start_x_fig = 0.1
    start_y_fig = 0.02
    bar_height_fig = 0.008

    bg_width_fig = scalebar_width_fig + 0.01
    bg_height_fig = bar_height_fig * 2 + 0.03

    bg_rect = Rectangle((start_x_fig - 0.005, start_y_fig - 0.005),
                        bg_width_fig, bg_height_fig,
                        facecolor='white', edgecolor='none', linewidth=0,
                        alpha=0.9, transform=fig.transFigure)
    fig.patches.append(bg_rect)

    segment_width_fig = scalebar_width_fig / segments
    segment_value = total_length / segments

    for i in range(segments):
        x_fig = start_x_fig + i * segment_width_fig

        color1 = 'black' if i % 2 == 0 else 'white'
        rect1 = Rectangle((x_fig, start_y_fig + bar_height_fig),
                          segment_width_fig, bar_height_fig,
                          facecolor=color1, edgecolor='black', linewidth=0.5,
                          transform=fig.transFigure)
        fig.patches.append(rect1)

        color2 = 'white' if i % 2 == 0 else 'black'
        rect2 = Rectangle((x_fig, start_y_fig),
                          segment_width_fig, bar_height_fig,
                          facecolor=color2, edgecolor='black', linewidth=0.5,
                          transform=fig.transFigure)
        fig.patches.append(rect2)

        text_x_fig = x_fig + segment_width_fig
        text_y_fig = start_y_fig + bar_height_fig * 2 + 0.005

        segment_val = (i + 1) * segment_value

        if units == 'km':
            if segment_val != int(segment_val):
                text_label = f'{segment_val:.1f}'
            else:
                text_label = f'{int(segment_val)}'
        else:
            text_label = f'{int(segment_val)}'

        if i == segments - 1:
            text_label += units

        fig.text(text_x_fig, text_y_fig, text_label,
                 ha='center', va='bottom', fontsize=9, fontweight='bold',
                 color='black', transform=fig.transFigure)

    fig.text(start_x_fig, start_y_fig + bar_height_fig * 2 + 0.005, '0',
             ha='center', va='bottom', fontsize=9, fontweight='bold',
             color='black', transform=fig.transFigure)


def generate_custom_intervals(min_val, max_val, divisions):
    """ì‚¬ìš©ì ì •ì˜ êµ¬ê°„ ìƒì„±"""
    diff = max_val - min_val
    div = divisions - 2
    target_interval = diff / div
    sorted_candidates = sorted(
        interval_candidates, key=lambda x: abs(x - target_interval))
    for best_interval in sorted_candidates:
        mid_val = min_val + diff / 2
        mid_aligned = round(mid_val / best_interval) * best_interval
        start = mid_aligned - best_interval * (div // 2)
        intervals = [f"{start}ë¯¸ë§Œ"]
        for i in range(div):
            lo = start + i * best_interval
            hi = lo + best_interval
            intervals.append(f"{lo}~{hi}")
        intervals.append(f"{hi}ì´ˆê³¼")
        return intervals, best_interval, start
    return [], 1, 0


def calculate_area_distribution(tif_path, interval_labels, bins):
    """ë©´ì  ë¶„í¬ ê³„ì‚°"""
    with rasterio.open(tif_path) as src:
        data = src.read(1)
        data = np.where((data == src.nodata) | np.isnan(data), np.nan, data)
        transform = src.transform
        pixel_area = abs(transform.a * transform.e)
    flat = data.flatten()
    flat = flat[~np.isnan(flat)]
    if len(flat) == 0:
        return [], 0
    hist, _ = np.histogram(flat, bins=bins)
    areas = hist * pixel_area
    total_area = np.sum(areas)
    percentages = areas / total_area * 100
    return list(zip(interval_labels, areas, percentages)), total_area


def extract_points_from_geometries(gdf, elevation_col='elevation'):
    """GDFì—ì„œ ê³ ë„ í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    xs, ys, zs = [], [], []
    if 'geometry' not in gdf.columns or gdf.geometry.isnull().all():
        return np.array([]), np.array([]), np.array([])

    for _, row in gdf.iterrows():
        geom = row.geometry
        z = row.get(elevation_col)

        if geom is None or geom.is_empty or z is None or not np.isfinite(z):
            continue

        geoms_to_process = [geom] if not geom.geom_type.startswith(
            'Multi') else list(geom.geoms)

        for part in geoms_to_process:
            if part.geom_type == 'Point':
                xs.append(part.x)
                ys.append(part.y)
                zs.append(z)
            elif part.geom_type in ('LineString', 'LinearRing'):
                for p in part.coords:
                    xs.append(p[0])
                    ys.append(p[1])
                    zs.append(z)
            elif part.geom_type == 'Polygon':
                for p in part.exterior.coords:
                    xs.append(p[0])
                    ys.append(p[1])
                    zs.append(z)
    return np.array(xs), np.array(ys), np.array(zs)


def generate_dem_from_db(shp_path, engine, pixel_size=1.0, buffer_m=100.0):
    """DB ë“±ê³ ì„  ë°ì´í„°ë¡œ DEMì„ ìƒì„±í•˜ê³  ì›ë³¸ ì˜ì—­ìœ¼ë¡œ í´ë¦¬í•‘í•˜ëŠ” í•¨ìˆ˜"""
    target_crs = "EPSG:5186"
    try:
        user_gdf = gpd.read_file(shp_path).to_crs(target_crs)
        if user_gdf.empty:
            print("  - ì…ë ¥ shp íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None, None, None

        user_bounds = user_gdf.total_bounds
        expanded_bounds = (
            user_bounds[0] - buffer_m, user_bounds[1] - buffer_m,
            user_bounds[2] + buffer_m, user_bounds[3] + buffer_m,
        )

        bbox_wkt = (
            f"POLYGON(({expanded_bounds[0]} {expanded_bounds[1]}, "
            f"{expanded_bounds[2]} {expanded_bounds[1]}, "
            f"{expanded_bounds[2]} {expanded_bounds[3]}, "
            f"{expanded_bounds[0]} {expanded_bounds[3]}, "
            f"{expanded_bounds[0]} {expanded_bounds[1]}))"
        )
        sql = f"SELECT geometry, elevation FROM kr_contour_map WHERE ST_Intersects(geometry, ST_GeomFromText('{bbox_wkt}', 5186));"
        
        contour_gdf = gpd.read_postgis(sql, engine, geom_col='geometry')
        if contour_gdf.empty:
            print("  - í•´ë‹¹ ì˜ì—­ì—ì„œ ë“±ê³ ì„  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None

        xs, ys, zs = extract_points_from_geometries(contour_gdf, 'elevation')
        if xs.size == 0:
            print("  - ë“±ê³ ì„  ë°ì´í„°ì—ì„œ ìœ íš¨í•œ ê³ ë„ í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None

        minx, miny, maxx, maxy = expanded_bounds
        grid_x, grid_y = np.mgrid[minx:maxx:pixel_size, miny:maxy:pixel_size]
        
        dem_grid_interpolated = griddata((xs, ys), zs, (grid_x, grid_y), method='linear', fill_value=np.nan)
        dem_grid = np.flipud(dem_grid_interpolated.T)

        transform = from_origin(expanded_bounds[0], expanded_bounds[3], pixel_size, pixel_size)
        
        with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmpfile:
            temp_dem_path = tmpfile.name
        
        with rasterio.open(
            temp_dem_path, 'w', driver='GTiff', height=dem_grid.shape[0], width=dem_grid.shape[1],
            count=1, dtype='float32', crs=target_crs, transform=transform, nodata=np.nan
        ) as dst:
            dst.write(dem_grid, 1)

        with rasterio.open(temp_dem_path) as src:
            clip_geoms = [g for g in user_gdf.geometry if g.is_valid and not g.is_empty]
            clipped_grid, clipped_transform = mask(src, clip_geoms, crop=True, nodata=np.nan)
            clipped_grid = clipped_grid[0]
        
        os.remove(temp_dem_path)
        
        return clipped_grid, clipped_transform, target_crs
    except Exception as e:
        print(f"  - DEM ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None



def create_visualization_with_hillshade(data, pixel_size, output_path, cmap_name, data_type='elevation',
                                        size_mm=25, divisions=None, hillshade_intensity=0.5):
    """ìŒì˜ íš¨ê³¼ë§Œì„ ì ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§€í˜• ì‹œê°í™”"""
    fig, ax = plt.subplots(figsize=(10, 9))

    # 1. ìŒì˜ê¸°ë³µë„ ìƒì„± (DEM ë°ì´í„° ê¸°ë°˜)
    hillshade = create_hillshade(data, azimuth=315, altitude=45)

    # 2. ì»¬ëŸ¬ë§µ ì„¤ì •
    if data_type == 'elevation' and divisions in elevation_colors:
        cmap = create_custom_elevation_colormap(
            elevation_colors[divisions], data, divisions)
    else:
        cmap = plt.cm.get_cmap(cmap_name)

    # 3. ìœ íš¨í•œ ë°ì´í„° ë§ˆìŠ¤í¬ ìƒì„±
    valid_mask = ~np.isnan(data)

    if np.any(valid_mask):
        # 4. ë°ì´í„°ë¥¼ 0-1ë¡œ ì •ê·œí™”
        vmin = np.nanmin(data[valid_mask])
        vmax = np.nanmax(data[valid_mask])

        if vmax > vmin:
            normalized_data = (data - vmin) / (vmax - vmin)
        else:
            normalized_data = np.full_like(data, 0.5)

        # 5. ìŒì˜ íš¨ê³¼ì™€ ìƒ‰ìƒ ë°ì´í„° ì¡°í•© (ê³±ì…ˆ ë¸”ë Œë”©)
        # hillshade ê°’ì„ 0.5~1.5 ë²”ìœ„ë¡œ ì¡°ì • (ë„ˆë¬´ ì–´ë‘ì›Œì§€ì§€ ì•Šê²Œ)
        hillshade_adjusted = 0.5 + hillshade * hillshade_intensity

        # ìƒ‰ìƒ ë°ì´í„°ì— ìŒì˜ ì ìš©
        shaded_data = normalized_data * hillshade_adjusted
        shaded_data = np.clip(shaded_data, 0, 1)  # 0-1 ë²”ìœ„ë¡œ ì œí•œ

        # ìœ íš¨ ë²”ìœ„ë§Œ ë§ˆìŠ¤í‚¹
        masked_shaded_data = np.ma.masked_where(~valid_mask, shaded_data)

        # 6. ì‹œê°í™” (ì›ë˜ ë°ì´í„° ë²”ìœ„ë¡œ ë§¤í•‘)
        im = ax.imshow(masked_shaded_data, cmap=cmap, interpolation='bilinear',
                       vmin=0, vmax=1)

    ax.axis('off')
    ax.set_position([0.05, 0.15, 0.9, 0.8])

    # 7. ìŠ¤ì¼€ì¼ë°” ì¶”ê°€
    scale_params = calculate_accurate_scalebar_params(
        pixel_size, data.shape, size_mm, fig, ax)
    draw_accurate_scalebar(fig, ax, pixel_size, scale_params, data.shape)

    plt.savefig(output_path, dpi=300, bbox_inches="tight", pad_inches=0.1,
                facecolor='white', edgecolor='none')
    plt.close()


def create_simple_visualization(data, pixel_size, output_path, cmap_name, data_type='elevation',
                                size_mm=25, divisions=None):
    """ê¸°ì¡´ ë°©ì‹ì˜ ë‹¨ìˆœ ì‹œê°í™” (ë¹„êµìš©) - ë¶„ì„ ë²”ìœ„ë§Œ"""
    fig, ax = plt.subplots(figsize=(10, 9))

    # ì»¬ëŸ¬ë§µ ì„¤ì •
    if data_type == 'elevation' and divisions in elevation_colors:
        cmap = create_custom_elevation_colormap(
            elevation_colors[divisions], data, divisions)
    else:
        cmap = plt.cm.get_cmap(cmap_name)

    # ìœ íš¨í•œ ë°ì´í„°ë§Œ í‘œì‹œ
    valid_mask = ~np.isnan(data)
    masked_data = np.ma.masked_where(~valid_mask, data)

    # ì‹œê°í™”
    im = ax.imshow(masked_data, cmap=cmap, interpolation='bilinear')
    ax.axis('off')
    ax.set_position([0.05, 0.15, 0.9, 0.8])

    # ìŠ¤ì¼€ì¼ë°” ì¶”ê°€
    scale_params = calculate_accurate_scalebar_params(
        pixel_size, data.shape, size_mm, fig, ax)
    draw_accurate_scalebar(fig, ax, pixel_size, scale_params, data.shape)

    plt.savefig(output_path, dpi=300, bbox_inches="tight", pad_inches=0.1,
                facecolor='white', edgecolor='none')
    plt.close()


# ========== ì‹¤í–‰ ==========
all_elev_stats = {10: [], 8: []}
all_slope_stats = {10: [], 8: []}
all_aspect_stats = []

shp_files = glob.glob(os.path.join(input_shp_dir, "*.shp"))
for shp_path in shp_files:
    name = os.path.splitext(os.path.basename(shp_path))[0]
    sub_folder = os.path.join(base_output_dir, name)
    os.makedirs(sub_folder, exist_ok=True)

    print(f"\nProcessing {name}...")
    if engine is None:
        print("DB ì—°ê²°ì´ ì—†ì–´ DEM ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        continue

    # 1. DBì—ì„œ DEM ìƒì„±
    print("  1/3: DBì—ì„œ ë“±ê³ ì„  ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ DEMì„ ìƒì„±í•©ë‹ˆë‹¤...")
    pixel_size = 1.0  # 1m í”½ì…€ ì‚¬ì´ì¦ˆë¡œ ê³ ì •
    dem_data, dem_transform, dem_crs = generate_dem_from_db(shp_path, engine, pixel_size=pixel_size)

    if dem_data is None:
        print(f"âŒ {name}ì— ëŒ€í•œ DEM ìƒì„± ì‹¤íŒ¨.")
        continue
    print("  âœ… DEM ìƒì„± ì™„ë£Œ.")

    dem_path = os.path.join(sub_folder, f"{name}_elevation.tif")
    with rasterio.open(
        dem_path, 'w', driver='GTiff', height=dem_data.shape[0], width=dem_data.shape[1],
        count=1, dtype='float32', crs=dem_crs, transform=dem_transform, nodata=np.nan
    ) as dst:
        dst.write(dem_data, 1)

    # 2. ìƒì„±ëœ DEMìœ¼ë¡œ ê²½ì‚¬/ê²½ì‚¬í–¥ ë¶„ì„
    print("  2/3: ìƒì„±ëœ DEMìœ¼ë¡œ ê²½ì‚¬ë„ ë° ê²½ì‚¬í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤...")
    slope_path, aspect_path = None, None
    try:
        import richdem as rd
        dem_rd = rd.LoadGDAL(dem_path)
        
        slope_arr = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')
        slope_path = os.path.join(sub_folder, f"{name}_slope.tif")
        with rasterio.open(slope_path, 'w', driver='GTiff', height=slope_arr.shape[0], width=slope_arr.shape[1], count=1, dtype='float32', crs=dem_crs, transform=dem_transform, nodata=np.nan) as dst:
            dst.write(slope_arr, 1)

        aspect_arr = rd.TerrainAttribute(dem_rd, attrib='aspect')
        aspect_path = os.path.join(sub_folder, f"{name}_aspect.tif")
        with rasterio.open(aspect_path, 'w', driver='GTiff', height=aspect_arr.shape[0], width=aspect_arr.shape[1], count=1, dtype='float32', crs=dem_crs, transform=dem_transform, nodata=np.nan) as dst:
            dst.write(aspect_arr, 1)
        print("  âœ… ê²½ì‚¬ë„/ê²½ì‚¬í–¥ ë¶„ì„ ì™„ë£Œ.")
    except ImportError:
        print("  âš ï¸ 'richdem' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê²½ì‚¬/ê²½ì‚¬í–¥ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    except Exception as e:
        print(f"  âŒ ê²½ì‚¬ë„/ê²½ì‚¬í–¥ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # 3. í†µê³„ ê³„ì‚° ë° ì‹œê°í™”
    print("  3/3: í†µê³„ ê³„ì‚° ë° ì‹œê°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
    gdf = gpd.read_file(shp_path).to_crs("EPSG:5186")
    subbasin_area = gdf.geometry.area.sum()
    area_km2 = subbasin_area / 1e6


    # í‘œê³  ë° ê²½ì‚¬ë„ ì²˜ë¦¬
    for kind, tif_path, stat_collector in [("elevation", dem_path, all_elev_stats),
                                           ("slope", slope_path, all_slope_stats)]:
        if not os.path.exists(tif_path):
            continue

        with rasterio.open(tif_path) as src:
            data = src.read(1)
            data = np.where((data == src.nodata) |
                            np.isnan(data), np.nan, data)

        flat = data.flatten()
        flat = flat[~np.isnan(flat)]
        if len(flat) == 0:
            continue

        min_val = np.min(flat)
        max_val = np.max(flat)

        # êµ¬ê°„ë³„ í†µê³„ ê³„ì‚°
        for divisions in [10, 8]:
            if kind == "slope":
                if divisions == 10:
                    edge_vals = list(range(0, 50, 5))
                    labels = [
                        "0ë¯¸ë§Œ"] + [f"{edge_vals[i]}~{edge_vals[i+1]}" for i in range(len(edge_vals)-1)] + ["45ì´ˆê³¼"]
                    bins = [float("-inf")] + edge_vals + [float("inf")]
                else:
                    edge_vals = list(range(0, 40, 5))
                    labels = [
                        "0ë¯¸ë§Œ"] + [f"{edge_vals[i]}~{edge_vals[i+1]}" for i in range(len(edge_vals)-1)] + ["35ì´ˆê³¼"]
                    bins = [float("-inf")] + edge_vals + [float("inf")]
            else:
                labels, interval_width, start = generate_custom_intervals(
                    min_val, max_val, divisions)
                bins = [start + i *
                        interval_width for i in range(divisions - 1)]
                bins = [float('-inf')] + bins + [float('inf')]

                # 0ë¯¸ë§Œ êµ¬ê°„ ì¡°ì •
                if labels[0].endswith("ë¯¸ë§Œ") and "0" in labels[0]:
                    stats, _ = calculate_area_distribution(
                        tif_path, labels, bins)
                    if stats and stats[0][1] == 0:
                        smaller_candidates = [
                            i for i in interval_candidates if i < interval_width]
                        if smaller_candidates:
                            new_interval = max(smaller_candidates)
                            mid_val = min_val + (max_val - min_val) / 2
                            mid_aligned = round(
                                mid_val / new_interval) * new_interval
                            start = mid_aligned - new_interval * \
                                ((divisions - 2) // 2)
                            labels = [f"{start}ë¯¸ë§Œ"] + [f"{start + i * new_interval}~{start + (i + 1) * new_interval}" for i in range(
                                divisions - 2)] + [f"{start + (divisions - 2) * new_interval}ì´ˆê³¼"]
                            bins = [start + i *
                                    new_interval for i in range(divisions - 1)]
                            bins = [float('-inf')] + bins + [float('inf')]

            # í†µê³„ ê³„ì‚° ë° ì €ì¥
            stats, _ = calculate_area_distribution(tif_path, labels, bins)
            stats_df = pd.DataFrame(stats, columns=["êµ¬ê°„", "ë©´ì ", "ë°±ë¶„ìœ¨"])
            stats_df.insert(0, "ëŒ€ìƒ", name)
            stats_df["ë³´ì •ë©´ì "] = stats_df["ë°±ë¶„ìœ¨"] / 100 * subbasin_area
            stats_df["ë³´ì •ë°±ë¶„ìœ¨"] = stats_df["ë³´ì •ë©´ì "] / subbasin_area * 100
            stats_df = stats_df.round(
                {"ë©´ì ": 2, "ë°±ë¶„ìœ¨": 2, "ë³´ì •ë©´ì ": 2, "ë³´ì •ë°±ë¶„ìœ¨": 2})
            stat_collector[divisions].append(stats_df)

            # ì‹œê°í™” ìƒì„±
            preview_dir = os.path.join(sub_folder, "visualizations", kind)
            os.makedirs(preview_dir, exist_ok=True)

            if kind == 'elevation':
                # í‘œê³ ëŠ” ì‚¬ìš©ì ì •ì˜ ìƒ‰ìƒë§Œ ì‚¬ìš©
                for size_mm in [25, 50]:
                    # ìŒì˜ íš¨ê³¼ ì ìš© ë²„ì „
                    output_path = os.path.join(preview_dir,
                                               f"{name}_{kind}_{divisions}div_hillshade_{size_mm}mm.png")
                    create_visualization_with_hillshade(data, pixel_size, output_path, None,
                                                        kind, size_mm, divisions, hillshade_intensity=0.7)

                    # ê¸°ì¡´ ë‹¨ìˆœ ë²„ì „ (ë¹„êµìš©)
                    output_path_simple = os.path.join(preview_dir,
                                                      f"{name}_{kind}_{divisions}div_simple_{size_mm}mm.png")
                    create_simple_visualization(data, pixel_size, output_path_simple, None,
                                                kind, size_mm, divisions)

            else:
                # ê²½ì‚¬ë„ëŠ” ê¸°ì¡´ ì»¬ëŸ¬ë§µ ì‚¬ìš© + DEM ê¸°ë°˜ ìŒì˜ê¸°ë³µë„
                for cmap in colormaps[kind]:
                    for size_mm in [25, 50]:
                        # ìŒì˜ê¸°ë³µë„ ì˜¤ë²„ë© ë²„ì „ (DEM ë°ì´í„° ì‚¬ìš©)
                        if dem_data is not None:
                            output_path = os.path.join(preview_dir,
                                                       f"{name}_{kind}_{divisions}div_{cmap}_hillshade_{size_mm}mm.png")
                            # ê²½ì‚¬ë„ ë°ì´í„° + DEM ê¸°ë°˜ ìŒì˜ê¸°ë³µë„ ì¡°í•©
                            fig, ax = plt.subplots(figsize=(10, 9))

                            # DEM ê¸°ë°˜ ìŒì˜ê¸°ë³µë„
                            hillshade = create_hillshade(
                                dem_data, azimuth=315, altitude=45)
                            cmap_obj = plt.cm.get_cmap(cmap)

                            # ê²½ì‚¬ë„ ë°ì´í„° ì‹œê°í™”
                            valid_mask = ~np.isnan(data)
                            if np.any(valid_mask):
                                vmin = np.nanmin(data[valid_mask])
                                vmax = np.nanmax(data[valid_mask])

                                # ìœ íš¨ ë²”ìœ„ë§Œ í‘œì‹œ
                                masked_data = np.ma.masked_where(
                                    ~valid_mask, data)
                                masked_hillshade = np.ma.masked_where(
                                    ~valid_mask, hillshade)

                                im1 = ax.imshow(masked_data, cmap=cmap_obj, interpolation='bilinear',
                                                vmin=vmin, vmax=vmax, alpha=1.0)
                                im2 = ax.imshow(masked_hillshade, cmap=cmap_obj, interpolation='bilinear',
                                                vmin=0, vmax=1, alpha=0.6)

                            ax.axis('off')
                            ax.set_position([0.05, 0.15, 0.9, 0.8])

                            scale_params = calculate_accurate_scalebar_params(
                                pixel_size, data.shape, size_mm, fig, ax)
                            draw_accurate_scalebar(
                                fig, ax, pixel_size, scale_params, data.shape)

                            plt.savefig(output_path, dpi=300, bbox_inches="tight", pad_inches=0.1,
                                        facecolor='white', edgecolor='none')
                            plt.close()

                        # ê¸°ì¡´ ë‹¨ìˆœ ë²„ì „ (ë¹„êµìš©)
                        output_path_simple = os.path.join(preview_dir,
                                                          f"{name}_{kind}_{divisions}div_{cmap}_simple_{size_mm}mm.png")
                        create_simple_visualization(data, pixel_size, output_path_simple, cmap,
                                                    kind, size_mm, divisions)

    # ê²½ì‚¬í–¥ ì²˜ë¦¬
    if os.path.exists(aspect_path):
        with rasterio.open(aspect_path) as src:
            data = src.read(1)
            data = np.where((data == src.nodata) |
                            np.isnan(data), np.nan, data)

        # ë¶í–¥ ì²˜ë¦¬
        north_mask = ((data >= 0) & (data < 22.5)) | (data >= 337.5)
        data_adjusted = np.where(north_mask, 0.0, data)

        with NamedTemporaryFile(suffix=".tif", delete=False) as tmpfile:
            with rasterio.open(aspect_path) as src:
                profile = src.profile
                profile.update(dtype=rasterio.float32, nodata=np.nan)
            with rasterio.open(tmpfile.name, 'w', **profile) as dst:
                dst.write(data_adjusted.astype(np.float32), 1)

        # í†µê³„ ê³„ì‚°
        stats, _ = calculate_area_distribution(
            tmpfile.name, aspect_labels, aspect_bins)
        os.remove(tmpfile.name)

        stats_df = pd.DataFrame(stats, columns=["ë°©í–¥", "ë©´ì ", "ë°±ë¶„ìœ¨"])
        stats_df.insert(0, "ëŒ€ìƒ", name)
        stats_df["ë³´ì •ë©´ì "] = stats_df["ë°±ë¶„ìœ¨"] / 100 * subbasin_area
        stats_df["ë³´ì •ë°±ë¶„ìœ¨"] = stats_df["ë³´ì •ë©´ì "] / subbasin_area * 100
        stats_df = stats_df.round({"ë©´ì ": 2, "ë°±ë¶„ìœ¨": 2, "ë³´ì •ë©´ì ": 2, "ë³´ì •ë°±ë¶„ìœ¨": 2})
        all_aspect_stats.append(stats_df)

        # ì‹œê°í™”
        preview_dir = os.path.join(sub_folder, "visualizations", "aspect")
        os.makedirs(preview_dir, exist_ok=True)

        for cmap in colormaps['aspect']:
            for size_mm in [25, 50]:
                # ë‹¨ìˆœ ë²„ì „ë§Œ
                output_path = os.path.join(preview_dir,
                                           f"{name}_aspect_{cmap}_{size_mm}mm.png")
                create_simple_visualization(data, pixel_size, output_path, cmap,
                                            'aspect', size_mm)

# ========== ê²°ê³¼ ì €ì¥ ==========
excel_path = os.path.join(base_output_dir, "êµ¬ê°„ë³„_í†µê³„ê²°ê³¼_hillshade.xlsx")
has_data = any(all_elev_stats[div] for div in [10, 8]) or any(
    all_slope_stats[div] for div in [10, 8]) or len(all_aspect_stats) > 0

if has_data:
    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        for div in [10, 8]:
            if all_elev_stats[div]:
                pd.concat(all_elev_stats[div], ignore_index=True).to_excel(
                    writer, sheet_name=f"elevation_{div}êµ¬ê°„", index=False)
            if all_slope_stats[div]:
                pd.concat(all_slope_stats[div], ignore_index=True).to_excel(
                    writer, sheet_name=f"slope_{div}êµ¬ê°„", index=False)
        if all_aspect_stats:
            pd.concat(all_aspect_stats, ignore_index=True).to_excel(
                writer, sheet_name="aspect_ë°©ìœ„", index=False)

    print(f"âœ… ì§€í˜• ë¶„ì„ ì‹œê°í™” ì™„ë£Œ! Excel ê²°ê³¼: {excel_path}")
    print(f"ğŸ”ï¸  í‘œê³ : ìŒì˜ íš¨ê³¼ ì ìš© (hillshade)")
    print(f"ğŸ“Š ê²½ì‚¬ë„/ê²½ì‚¬í–¥: ê¸°ë³¸ ì‹œê°í™”")
    print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: 'visualizations' í´ë”")
else:
    print("ì €ì¥í•  í†µê³„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
