
import streamlit as st
import os
import geopandas as gpd
import pandas as pd
from sqlalchemy import create_engine
import warnings
from utils.config import get_db_engine
from utils.theme_util import apply_styles

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ë°ì´í„° ë¹„êµ - ì§€í˜• ë¶„ì„ ì„œë¹„ìŠ¤", page_icon="ğŸ”", layout="wide")
apply_styles()

# --- 1. ì‚¬ìš©ì ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ë‚´ì—ì„œ ê³ ì •) ---

# ë¡œì»¬ ë°ì´í„°ê°€ ìˆëŠ” ë£¨íŠ¸ í´ë”
LOCAL_DATA_ROOT = r'C:\dev\terrainAnalyzer_st\utils\soil'
# ë¹„êµí•  DB í…Œì´ë¸” ì´ë¦„
DB_TABLE_NAME = 'kr_soil_map'
# ë¡œì»¬ ë°ì´í„°ì˜ ì˜ˆìƒ ì¢Œí‘œê³„ (EPSG ì½”ë“œ)
LOCAL_DATA_CRS = 'EPSG:5174'


# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---

@st.cache_data
def read_local_data():
    """ë¡œì»¬ Shapefileë“¤ì„ ì½ì–´ í•˜ë‚˜ì˜ GeoDataFrameìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    shapefiles_to_load = []
    st.write(f"'{LOCAL_DATA_ROOT}' í´ë”ì—ì„œ ë¡œì»¬ Shapefile ê²€ìƒ‰ ì¤‘...")
    for dirpath, _, filenames in os.walk(LOCAL_DATA_ROOT):
        for filename in filenames:
            if filename.lower().endswith('.shp'):
                shapefiles_to_load.append(os.path.join(dirpath, filename))
    
    if not shapefiles_to_load:
        st.error("ì˜¤ë¥˜: ë¡œì»¬ Shapefileì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    st.write(f"ì´ {len(shapefiles_to_load)}ê°œì˜ ë¡œì»¬ Shapefileì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í•©ì¹˜ëŠ” ì¤‘...")
    
    progress_bar = st.progress(0)
    gdf_list = []
    for i, shp_path in enumerate(shapefiles_to_load):
        try:
            gdf = gpd.read_file(shp_path, encoding='euc-kr')
            gdf_list.append(gdf)
        except Exception as e:
            st.warning(f"'{os.path.basename(shp_path)}' íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        progress_bar.progress((i + 1) / len(shapefiles_to_load))

    if not gdf_list:
        st.error("ì˜¤ë¥˜: ìœ íš¨í•œ Shapefileì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        return None

    combined_gdf = pd.concat(gdf_list, ignore_index=True)
    combined_gdf = gpd.GeoDataFrame(combined_gdf, geometry=combined_gdf.geometry)
    combined_gdf.set_crs(LOCAL_DATA_CRS, allow_override=True, inplace=True)
    st.write("ë¡œì»¬ ë°ì´í„° ì½ê¸° ë° ë³‘í•© ì™„ë£Œ!")
    return combined_gdf

@st.cache_data
def read_db_data(_engine):
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í…Œì´ë¸”ì„ ì½ì–´ GeoDataFrameìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    st.write(f"ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{DB_TABLE_NAME}' í…Œì´ë¸”ì„ ì½ëŠ” ì¤‘...")
    try:
        db_gdf = gpd.read_postgis(f"SELECT * FROM {DB_TABLE_NAME}", _engine, geom_col='geometry')
        st.write("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì½ê¸° ì™„ë£Œ!")
        return db_gdf
    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{DB_TABLE_NAME}' í…Œì´ë¸”ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {e}")
        return None

# --- 3. Streamlit UI êµ¬ì„± ---

st.markdown("### ğŸ” ë¡œì»¬ vs ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ë¹„êµ")
st.write("""
ì´ í˜ì´ì§€ëŠ” ë¡œì»¬ì— ì €ì¥ëœ í† ì–‘ë„ ë°ì´í„°ì™€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ í† ì–‘ë„ ë°ì´í„°ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
""")

if st.button("ë°ì´í„° ë¹„êµ ì‹¤í–‰"):
    
    with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•˜ëŠ” ì¤‘..."):
        try:
            engine = get_db_engine()
            with engine.connect() as connection:
                st.success("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            st.stop()

    st.markdown("---")
    
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“ ë¡œì»¬ íŒŒì¼ ë°ì´í„°")
        with st.spinner("ë¡œì»¬ ë°ì´í„° ì²˜ë¦¬ ì¤‘..."):
            local_gdf = read_local_data()

    with col2:
        st.subheader("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„°")
        with st.spinner("DB ë°ì´í„° ì²˜ë¦¬ ì¤‘..."):
            db_gdf = read_db_data(engine)

    st.markdown("---")

    if local_gdf is not None and db_gdf is not None:
        st.subheader("ğŸ“Š ë¹„êµ ê²°ê³¼ ìš”ì•½")

        # 1. ë°ì´í„° ê°œìˆ˜ ë¹„êµ
        st.markdown("#### 1. ë°ì´í„° ê°œìˆ˜ (Features)")
        c1, c2 = st.columns(2)
        c1.metric("ë¡œì»¬ íŒŒì¼", f"{len(local_gdf):,} ê°œ")
        c2.metric("ë°ì´í„°ë² ì´ìŠ¤", f"{len(db_gdf):,} ê°œ")

        # 2. ì¢Œí‘œê³„ ë¹„êµ
        st.markdown("#### 2. ì¢Œí‘œê³„ (CRS)")
        c1, c2 = st.columns(2)
        with c1:
            st.write("**ë¡œì»¬ íŒŒì¼**")
            st.code(local_gdf.crs, language=None)
        with c2:
            st.write("**ë°ì´í„°ë² ì´ìŠ¤**")
            st.code(db_gdf.crs, language=None)

        # 3. ì „ì²´ ì˜ì—­ ë¹„êµ
        st.markdown("#### 3. ì „ì²´ ì˜ì—­ (Total Bounds)")
        st.write("**ë¡œì»¬ íŒŒì¼**")
        st.code(local_gdf.total_bounds, language=None)
        st.write("**ë°ì´í„°ë² ì´ìŠ¤**")
        st.code(db_gdf.total_bounds, language=None)

        # 4. ì»¬ëŸ¼ ì •ë³´ ë¹„êµ
        st.markdown("#### 4. ì»¬ëŸ¼(ì†ì„±) ëª©ë¡")
        local_cols = set(local_gdf.columns)
        db_cols = set(db_gdf.columns)
        c1, c2 = st.columns(2)
        c1.metric("ë¡œì»¬ íŒŒì¼ ì»¬ëŸ¼ ìˆ˜", len(local_cols))
        c2.metric("ë°ì´í„°ë² ì´ìŠ¤ ì»¬ëŸ¼ ìˆ˜", len(db_cols))
        
        if local_cols == db_cols:
            st.success("ì»¬ëŸ¼ êµ¬ì„±ì´ ë™ì¼í•©ë‹ˆë‹¤.")
        else:
            st.warning("ì»¬ëŸ¼ êµ¬ì„±ì´ ë‹¤ë¦…ë‹ˆë‹¤.")
            if len(local_cols - db_cols) > 0:
                st.write("**ë¡œì»¬ì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:**")
                st.code(sorted(list(local_cols - db_cols)), language=None)
            if len(db_cols - local_cols) > 0:
                st.write("**DBì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:**")
                st.code(sorted(list(db_cols - local_cols)), language=None)

        # 5. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        st.markdown("#### 5. ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 5í–‰)")
        st.write("**ë¡œì»¬ íŒŒì¼ ë°ì´í„°**")
        st.dataframe(local_gdf.head())
        st.write("**ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„°**")
        st.dataframe(db_gdf.head())

    else:
        st.error("ë°ì´í„° ì¤‘ í•˜ë‚˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í•˜ì—¬ ë¹„êµë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
