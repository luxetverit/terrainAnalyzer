import datetime
import gc
import io
import platform

import matplotlib.patches as mpatches
import matplotlib.patheffects as path_effects
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st
from matplotlib.colors import BoundaryNorm, ListedColormap
from matplotlib.patches import Polygon, Rectangle
from scipy.ndimage import zoom

from utils.color_palettes import get_landcover_colormap, get_palette
from utils.plot_helpers import (add_north_arrow, add_scalebar_vector,
                                adjust_ax_limits,
                                calculate_accurate_scalebar_params,
                                create_hillshade, create_padded_fig_ax,
                                draw_accurate_scalebar, generate_aspect_bins,
                                generate_custom_intervals,
                                generate_slope_intervals)
from utils.theme_util import apply_styles

# --- 0. Matplotlib Font Configuration ---
if platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
else:
    # For Linux, ensure 'NanumGothic' is installed.
    # sudo apt-get install -y fonts-nanum*
    plt.rc('font', family='NanumGothic')
plt.rcParams['axes.unicode_minus'] = False

# --- 1. Page Configuration and Styling ---
st.set_page_config(page_title="ë¶„ì„ ê²°ê³¼ - ì§€í˜• ë¶„ì„ ì„œë¹„ìŠ¤",
                   page_icon="ğŸ“Š",
                   layout="wide",
                   initial_sidebar_state="collapsed")
apply_styles()

# --- 2. Session State Check ---
if 'dem_results' not in st.session_state:
    st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í™ˆ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    if st.button("í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.switch_page("app.py")
    st.stop()

# --- 3. Data Loading from Session ---
dem_results = st.session_state.dem_results
selected_types = st.session_state.get('selected_analysis_types', [])
matched_sheets = st.session_state.get('matched_sheets', [])
analysis_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

# --- 4. Page Header ---
st.markdown('''<div class="page-header"><h1>ë¶„ì„ ê²°ê³¼</h1><p>ì„ íƒí•˜ì‹  í•­ëª©ì— ëŒ€í•œ ì§€í˜• ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.</p></div>''',
            unsafe_allow_html=True)

# --- 6. 2D Analysis Results (in Tabs) ---
st.markdown("### ğŸ“ˆ 2D ìƒì„¸ ë¶„ì„ ê²°ê³¼")
analysis_map = {
    'elevation': {'title': "í‘œê³  ë¶„ì„", 'unit': "m", 'binned_label': "í‘œê³  êµ¬ê°„ë³„ ë©´ì "},
    'slope': {'title': "ê²½ì‚¬ ë¶„ì„", 'unit': "Â°", 'binned_label': "ê²½ì‚¬ êµ¬ê°„ë³„ ë©´ì "},
    'aspect': {'title': "ê²½ì‚¬í–¥ ë¶„ì„", 'unit': "Â°", 'binned_label': "ê²½ì‚¬í–¥ êµ¬ê°„ë³„ ë©´ì "},
    'soil': {'title': "í† ì–‘ë„ ë¶„ì„", 'unit': "mÂ²", 'binned_label': "í† ì–‘ ì¢…ë¥˜ë³„ ë©´ì ", 'class_col': 'soilsy', 'legend_title': 'í† ì„±'},
    'hsg': {'title': "ìˆ˜ë¬¸í•™ì  í† ì–‘êµ°", 'unit': "mÂ²", 'binned_label': "HSG ë“±ê¸‰ë³„ ë©´ì ", 'class_col': 'hg', 'legend_title': 'HSG ë“±ê¸‰'},
    'landcover': {'title': "í† ì§€í”¼ë³µë„", 'unit': "mÂ²", 'binned_label': "í† ì§€í”¼ë³µë³„ ë©´ì ", 'class_col': 'l2_name', 'legend_title': 'í† ì§€í”¼ë³µ'},
}
valid_selected_types = [t for t in selected_types if t in dem_results]

if not valid_selected_types:
    st.info("í‘œì‹œí•  2D ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # Loop through each analysis type and display its results sequentially
    for analysis_type in valid_selected_types:
        with st.container(border=True):
            st.markdown(
                f"### ğŸ“ˆ {analysis_map.get(analysis_type, {}).get('title', analysis_type)}")

            results = dem_results[analysis_type]
            stats = results.get('stats')
            grid = results.get('grid')
            gdf = results.get('gdf')

            # [OPTIMIZATION 1] Halve memory usage of the grid by changing data type
            if grid is not None:
                grid = grid.astype(np.float32)

                # [OPTIMIZATION 2 & Scalebar Fix] Dynamic Downsampling and Pixel Size Adjustment
                effective_pixel_size = st.session_state.get('pixel_size', 1.0)
                PIXEL_THRESHOLD = 5_000_000  # Approx 2500x2000 image
                if grid.size > PIXEL_THRESHOLD:
                    downsample_factor = (PIXEL_THRESHOLD / grid.size) ** 0.5
                    st.info(
                        f"â„¹ï¸ ë¶„ì„ ì˜ì—­ì´ ë§¤ìš° ì»¤ì„œ ì‹œê°í™” í•´ìƒë„ë¥¼ ì›ë³¸ì˜ {downsample_factor:.1%}ë¡œ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.")
                    # order=1 for bilinear interpolation
                    grid = zoom(grid, downsample_factor, order=1)
                    # Adjust pixel size to match the new resolution for accurate scale bar
                    effective_pixel_size = effective_pixel_size / downsample_factor

            if stats:
                st.markdown("#### ìš”ì•½ í†µê³„")
                cols = st.columns(3)
                cols[0].metric(
                    label="ìµœì†Œê°’", value=f"{stats.get('min', 0):.2f} {analysis_map.get(analysis_type, {}).get('unit', '')}")
                cols[1].metric(
                    label="ìµœëŒ€ê°’", value=f"{stats.get('max', 0):.2f} {analysis_map.get(analysis_type, {}).get('unit', '')}")
                cols[2].metric(
                    label="í‰ê· ê°’", value=f"{stats.get('mean', 0):.2f} {analysis_map.get(analysis_type, {}).get('unit', '')}")
                st.markdown("---_---")

                title = analysis_map.get(analysis_type, {}).get(
                    'title', analysis_type)
                with st.spinner(f"'{title}' ë¶„ì„ë„ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    # --- Unified DEM Analysis Plotting ---

                    # Retrieve all visualization info from the results dictionary
                    bins = results.get('bins')
                    labels = results.get('labels')
                    palette_name = results.get('palette_name')

                    if not all([bins, labels, palette_name]):
                        st.warning(f"'{title}'ì— ëŒ€í•œ ì‹œê°í™” ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    palette_data = get_palette(palette_name)
                    if not palette_data:
                        st.warning(f"'{palette_name}' íŒ”ë ˆíŠ¸ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    # For aspect, reorder the palette to put 'Flat' first, matching the data processing.
                    if analysis_type == 'aspect':
                        flat_label_item = None
                        for item in palette_data:
                            if item['bin_label'].strip().lower() == 'flat':
                                flat_label_item = item
                                break

                        if flat_label_item:
                            palette_data.remove(flat_label_item)
                            palette_data.insert(0, flat_label_item)

                    colors = [item['hex_color'] for item in palette_data]

                    # Create colormap and normalization
                    cmap = ListedColormap(colors)
                    norm = BoundaryNorm(bins, cmap.N)

                    # --- Plotting ---
                    fig, ax = create_padded_fig_ax(figsize=(10, 8))
                    ax.set_title(title, fontsize=16, pad=20)

                    use_hillshade = False
                    if analysis_type == 'elevation':
                        use_hillshade = st.toggle(
                            "ìŒì˜ê¸°ë³µë„ ì¤‘ì²©", value=True, key=f"hillshade_{analysis_type}")
                        if use_hillshade:
                            hillshade = create_hillshade(grid)
                            rgba_data = cmap(norm(grid))
                            intensity = 0.7
                            hillshade_adjusted = 0.5 + hillshade * intensity
                            for i in range(3):
                                rgba_data[:, :, i] *= hillshade_adjusted
                            valid_mask = ~np.isnan(grid)
                            rgba_data[~valid_mask, 3] = 0
                            ax.imshow(np.clip(rgba_data, 0, 1), origin='upper')
                            del hillshade, hillshade_adjusted, rgba_data
                            gc.collect()
                        else:
                            ax.imshow(np.ma.masked_invalid(
                                grid), cmap=cmap, norm=norm)
                    else:
                        ax.imshow(np.ma.masked_invalid(
                            grid), cmap=cmap, norm=norm)

                    # ë“±ê³ ì„  ì¶”ê°€ (50m ê°„ê²©)
                    if analysis_type == 'elevation':
                        min_val, max_val = stats.get(
                            'min', 0), stats.get('max', 1)
                        level_interval = 100
                        start_level = np.ceil(
                            min_val / level_interval) * level_interval
                        end_level = np.floor(
                            max_val / level_interval) * level_interval

                        if start_level < end_level:
                            contour_levels = np.arange(
                                start_level, end_level + 1, level_interval)
                        else:
                            contour_levels = np.linspace(min_val, max_val, 10)

                        contour = ax.contour(
                            grid, levels=contour_levels, colors='k', alpha=0.3, linewidths=0.7)

                        # ë“±ê³ ì„  ë¼ë²¨ ì¶”ê°€ (50m ê°„ê²©)
                        label_interval = 100
                        start_label_level = np.ceil(
                            min_val / label_interval) * label_interval
                        end_label_level = np.floor(
                            max_val / label_interval) * label_interval

                        if start_label_level < end_label_level:
                            label_levels = np.arange(
                                start_label_level, end_label_level + 1, label_interval)
                        else:
                            # 100m ê°„ê²© ë¼ë²¨ì„ í‘œì‹œí•  ìˆ˜ ì—†ìœ¼ë©´ ëª¨ë“  ë“±ê³ ì„ ì— ë¼ë²¨ í‘œì‹œ
                            label_levels = contour_levels

                        clabels = ax.clabel(
                            contour, levels=label_levels, inline=True, fontsize=8, fmt='%.0f')
                        # [Readability Improvement] Add a white stroke to contour labels
                        plt.setp(clabels, fontweight='bold', path_effects=[
                                 path_effects.withStroke(linewidth=3, foreground='w')])

                    # --- Legend and Map Elements ---
                    patches = [mpatches.Patch(color=color, label=label)
                               for color, label in zip(colors, labels)]
                    # legend_title = analysis_map[analysis_type].get('binned_label', 'ë²”ë¡€')
                    legend_title = 'ë²”  ë¡€'
                    legend = ax.legend(handles=patches, title=legend_title,
                                       bbox_to_anchor=(0.1, 0.1), loc='lower left',
                                       bbox_transform=fig.transFigure,
                                       fontsize='small', frameon=True, framealpha=1,
                                       edgecolor='black')
                    legend.get_title().set_fontweight('bold')

                    adjust_ax_limits(ax)
                    add_north_arrow(ax)
                    scale_params = calculate_accurate_scalebar_params(
                        effective_pixel_size, grid.shape, 25, fig, ax)
                    draw_accurate_scalebar(
                        fig, ax, effective_pixel_size, scale_params, grid.shape)
                    ax.axis('off')

                    # --- Display and Download ---
                    img_buffer = io.BytesIO()
                    fig.savefig(img_buffer, format='png',
                                bbox_inches='tight', dpi=150)
                    img_buffer.seek(0)
                    st.pyplot(fig)
                    plt.close(fig)

                    file_name_suffix = ""
                    if analysis_type == 'elevation' and use_hillshade:
                        file_name_suffix = "_hillshade"

                    st.download_button(
                        label="PNG ì´ë¯¸ì§€ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=img_buffer,
                        file_name=f"{analysis_type}_analysis{file_name_suffix}_{datetime.datetime.now().strftime('%Y%m%d')}.png",
                        mime="image/png",
                        key=f"download_{analysis_type}"
                    )

            elif gdf is not None and not gdf.empty:
                title = analysis_map.get(
                    analysis_type, {}).get('title', analysis_type)
                with st.spinner(f"'{title}' ë¶„ì„ë„ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    fig, ax = create_padded_fig_ax(figsize=(10, 10))
                    type_info = analysis_map.get(analysis_type, {})
                    class_col = type_info.get('class_col')

                    # Landcover custom color logic
                    if analysis_type == 'landcover':
                        # Check if color map is loaded and required columns exist
                        color_map = get_landcover_colormap()
                        if color_map and 'l2_code' in gdf.columns and 'l2_name' in gdf.columns:
                            gdf['plot_color'] = gdf['l2_code'].map(color_map)
                            # Plot with the specified colors, handling potential missing colors
                            gdf.plot(ax=ax, color=gdf['plot_color'].fillna(
                                '#FFFFFF'), linewidth=0.5, edgecolor='k')

                            # Create a custom legend
                            unique_cats = gdf[['l2_code', 'l2_name']].drop_duplicates(
                            ).sort_values(by='l2_code')
                            patches = []
                            for _, row in unique_cats.iterrows():
                                code = row['l2_code']
                                name = row['l2_name']
                                # Default to white if not in map
                                color = color_map.get(code, '#FFFFFF')
                                patch = mpatches.Patch(
                                    color=color, label=f'{name} ({code})')
                                patches.append(patch)

                            if patches:
                                n_items = len(patches)
                                n_cols = (n_items + 19) // 20
                                ax.legend(handles=patches, title=type_info.get('legend_title', 'ë¶„ë¥˜'),
                                          bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small',
                                          ncol=n_cols)
                        else:
                            # Fallback for landcover if custom colors fail
                            gdf.plot(column=class_col, ax=ax, legend=True, categorical=True,
                                     legend_kwds={'title': type_info.get('legend_title', 'ë¶„ë¥˜'), 'bbox_to_anchor': (1.05, 1), 'loc': 'upper left'})

                    # Logic for other vector types (soil, hsg)
                    else:
                        if class_col and class_col in gdf.columns:
                            gdf_plot = gdf[gdf[class_col].notna()].copy()
                            unique_cats = sorted(gdf_plot[class_col].unique())

                            num_cats = len(unique_cats)
                            # Use 'tab20' for up to 20 categories, then a sampled colormap for more
                            if num_cats <= 20:
                                cmap = plt.cm.get_cmap('tab20', num_cats)
                                colors = cmap.colors
                            else:
                                cmap = plt.cm.get_cmap('viridis', num_cats)
                                colors = cmap(np.linspace(0, 1, num_cats))

                            color_map = {cat: color for cat,
                                         color in zip(unique_cats, colors)}
                            gdf_plot['plot_color'] = gdf_plot[class_col].map(
                                color_map)

                            gdf_plot.plot(
                                ax=ax, color=gdf_plot['plot_color'], linewidth=0.5, edgecolor='k')

                            patches = [mpatches.Patch(
                                color=color, label=cat) for cat, color in color_map.items()]

                            if patches:
                                n_items = len(patches)
                                n_cols = (n_items + 19) // 20
                                ax.legend(handles=patches, title=type_info.get('legend_title', 'ë¶„ë¥˜'),
                                          bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small',
                                          ncol=n_cols)
                        else:
                            gdf.plot(ax=ax)
                            if class_col:
                                st.warning(
                                    f"ì£¼ì˜: ë¶„ì„ì— í•„ìš”í•œ ë¶„ë¥˜ ì»¬ëŸ¼ '{class_col}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. DB í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(gdf.columns)}")
                            else:
                                st.warning("ë¶„ì„ ìœ í˜•ì— ëŒ€í•œ ë¶„ë¥˜ ì»¬ëŸ¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                    adjust_ax_limits(ax)
                    add_north_arrow(ax)
                    add_scalebar_vector(ax, dx=1.0)
                    ax.axis('off')
                    st.pyplot(fig)
                    plt.close(fig)  # Close figure to save memory
            else:
                st.info("ì‹œê°í™”í•  2D ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.markdown("---")  # Add a separator between analyses
# --- 7. Summary and Downloads ---
st.markdown("### ğŸ“‹ ìš”ì•½ ë° ë‹¤ìš´ë¡œë“œ")
st.markdown("#### ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ")

summary_lines = []
summary_lines.append(f"ë¶„ì„ ì¼ì‹œ: {analysis_date}")
summary_lines.append(
    f"ë¶„ì„ ëŒ€ìƒ: {st.session_state.get('uploaded_file_name', 'N/A')}")
if len(matched_sheets) > 20:
    summary_lines.append(
        f"ì‚¬ìš©ëœ ë„ì—½: {len(matched_sheets)}ê°œ ({', '.join(matched_sheets[:20])}...)")
else:
    summary_lines.append(
        f"ì‚¬ìš©ëœ ë„ì—½: {len(matched_sheets)}ê°œ ({', '.join(matched_sheets)})")
summary_lines.append("")

pixel_size = st.session_state.get('pixel_size', 1.0)
area_per_pixel = pixel_size * pixel_size

for analysis_type in valid_selected_types:
    stats = dem_results[analysis_type].get('stats')
    binned_stats = dem_results[analysis_type].get('binned_stats')
    gdf = dem_results[analysis_type].get('gdf')
    title_info = analysis_map.get(analysis_type, {})

    summary_lines.append(f"--- {title_info.get('title', analysis_type)} ---")

    # Calculate total area first to use for percentages
    total_area_m2 = 0
    if stats:
        total_area_m2 = stats.get('area', 0) * area_per_pixel
        unit = title_info.get('unit', '')
        summary_lines.append(f"- ìµœì†Œê°’: {stats.get('min', 0):.2f} {unit}")
        summary_lines.append(f"- ìµœëŒ€ê°’: {stats.get('max', 0):.2f} {unit}")
        summary_lines.append(f"- í‰ê· ê°’: {stats.get('mean', 0):.2f} {unit}")
        summary_lines.append(f"- ë¶„ì„ ë©´ì : {int(total_area_m2):,} mÂ²")
    elif gdf is not None and not gdf.empty:
        gdf['area'] = gdf.geometry.area
        total_area_m2 = gdf.area.sum()

    if binned_stats:
        summary_lines.append(f"\n[{title_info.get('binned_label', 'êµ¬ê°„ë³„ í†µê³„')}]")
        for row in binned_stats:
            binned_area_m2 = row['area'] * area_per_pixel
            percentage = (binned_area_m2 / total_area_m2 *
                          100) if total_area_m2 > 0 else 0
            summary_lines.append(
                f"- {row['bin_range']} {title_info.get('unit', '')}: {int(binned_area_m2):,} mÂ² ({percentage:.1f} %)")

    if gdf is not None and not gdf.empty:
        class_col = title_info.get('class_col')
        if class_col and class_col in gdf.columns:
            summary = gdf.groupby(class_col)[
                'area'].sum().sort_values(ascending=False)
            summary_lines.append(
                f"\n[{title_info.get('binned_label', 'ì¢…ë¥˜ë³„ í†µê³„')}]")
            for item, area in summary.items():
                percentage = (area / total_area_m2 *
                              100) if total_area_m2 > 0 else 0
                summary_lines.append(
                    f"- {item}: {int(area):,} mÂ² ({percentage:.1f} %)")
        else:
            summary_lines.append(f"- ì´ ë¶„ì„ ë©´ì : {int(total_area_m2):,} mÂ²")
            if class_col:
                summary_lines.append(
                    f"- (ìƒì„¸ ë©´ì  í†µê³„ë¥¼ ê³„ì‚°í•˜ë ¤ë©´ '{class_col}' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.)")

    summary_lines.append("")

summary_text = "\n".join(summary_lines)
st.text_area("ë¶„ì„ ê²°ê³¼ ìš”ì•½", summary_text, height=300)
st.download_button("ë¶„ì„ ê²°ê³¼(.txt) ë‹¤ìš´ë¡œë“œ", summary_text, "analysis_summary.txt")


# --- 8. Footer ---
st.markdown("---_---")
if st.button("ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
    for key in list(st.session_state.keys()):
        if key not in ['upload_counter']:
            del st.session_state[key]
    st.switch_page("app.py")
    st.switch_page("app.py")
    st.switch_page("app.py")
